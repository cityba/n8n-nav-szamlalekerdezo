import type { BaseChatModel } from '@langchain/core/language_models/chat_models';
import type { LangChainTracer } from '@langchain/core/tracers/tracer_langchain';
import { MemorySaver } from '@langchain/langgraph';
import type { Logger } from '@n8n/backend-common';
import type { INodeTypeDescription, IRunExecutionData, IWorkflowBase, NodeExecutionSchema } from 'n8n-workflow';
export interface WorkflowBuilderAgentConfig {
    parsedNodeTypes: INodeTypeDescription[];
    llmSimpleTask: BaseChatModel;
    llmComplexTask: BaseChatModel;
    logger?: Logger;
    checkpointer?: MemorySaver;
    tracer?: LangChainTracer;
}
export interface ChatPayload {
    message: string;
    workflowContext?: {
        executionSchema?: NodeExecutionSchema[];
        currentWorkflow?: Partial<IWorkflowBase>;
        executionData?: IRunExecutionData['resultData'];
    };
}
export declare class WorkflowBuilderAgent {
    private checkpointer;
    private parsedNodeTypes;
    private llmSimpleTask;
    private llmComplexTask;
    private logger?;
    private tracer?;
    constructor(config: WorkflowBuilderAgentConfig);
    private createWorkflow;
    getState(workflowId: string, userId?: string): Promise<import("@langchain/langgraph").StateSnapshot>;
    static generateThreadId(workflowId?: string, userId?: string): string;
    chat(payload: ChatPayload, userId?: string): AsyncGenerator<import("./types").StreamOutput, void, unknown>;
    getSessions(workflowId: string | undefined, userId?: string): Promise<{
        sessions: {
            sessionId: string;
            messages: Record<string, unknown>[];
            lastUpdated: string;
        }[];
    }>;
}
